{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "uses auto mpg datasets.The data is technical spec of cars. Attribute Information: \n",
    "1.mpg (miles per gallon): continuous \n",
    "2. cylinders: multi-valued discrete \n",
    "3. displacement: continuous\n",
    "4. horsepower: continuous \n",
    "5. weight: continuous \n",
    "6. acceleration: continuous \n",
    "7. model year: multivalued discrete \n",
    "8. origin: multi-valued discrete \n",
    "9. car name: string (unique for each instance)\n",
    "    \n",
    "Build an ensemble model to predict the origin. Experiment with the ensemble methods to achieve\n",
    "the highest accuracy. Use random_state=5 to split the dataset into training and test data.\n",
    "Post your solution on Lab - Ensemble Learning Submission on elearn@usm. Make sure you to\n",
    "include your name, matrix number and lab# on the submission post. Format: in .ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this lab, we will be implementing Ensemble Learning using Scikit Learn (sklearn).\n",
    "Import the standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the standard modules to be used in this lab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.read_csv('heart.csv')\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can see that all the ranges of the features are not the same. This may cause a problem where\n",
    "a small change in a feature might not affect the other. So we normalize the ranges of the features\n",
    "to a uniform range which in this case 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "normData = scaler.fit_transform(data_pd.iloc[:,0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>0.244292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.283105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.251142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex        cp  trestbps      chol  fbs  restecg   thalach  exang  \\\n",
       "0  0.708333  1.0  1.000000  0.481132  0.244292  1.0      0.0  0.603053    0.0   \n",
       "1  0.166667  1.0  0.666667  0.339623  0.283105  0.0      0.5  0.885496    0.0   \n",
       "2  0.250000  0.0  0.333333  0.339623  0.178082  0.0      0.0  0.770992    0.0   \n",
       "3  0.562500  1.0  0.333333  0.245283  0.251142  0.0      0.5  0.816794    0.0   \n",
       "4  0.583333  0.0  0.000000  0.245283  0.520548  0.0      0.5  0.702290    1.0   \n",
       "\n",
       "    oldpeak  slope   ca      thal  target  \n",
       "0  0.370968    0.0  0.0  0.333333       1  \n",
       "1  0.564516    0.0  0.0  0.666667       1  \n",
       "2  0.225806    1.0  0.0  0.666667       1  \n",
       "3  0.129032    1.0  0.0  0.666667       1  \n",
       "4  0.096774    1.0  0.0  0.666667       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normData_pd = pd.DataFrame(normData)\n",
    "normData_pd.columns = data_pd.columns[:-1]\n",
    "normData_pd['target'] = data_pd['target']\n",
    "normData_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(normData_pd.iloc[:,0:-1],\n",
    "normData_pd.iloc[:,-1],test_size=0.3, random_state=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting\n",
    "\n",
    "Let’s build a voting classifier using Decision Tree, Support Vector Machine and Logistic Regression\n",
    "classifiers. The voting scheme is set to ‘soft’. That’s means every individual classifier provides a\n",
    "probability value of an example belongs to a particular target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "svc = SVC(gamma='auto', probability=True) # probability parameter is set to true to output the probability score.\n",
    "lgc = LogisticRegression()\n",
    "classifiers = []\n",
    "classifiers.append(('c1', dtc))\n",
    "classifiers.append(('c2', svc))\n",
    "classifiers.append(('c3', lgc))\n",
    "# voting: hard (class label)/soft (sum of probability)\n",
    "ensemble = VotingClassifier(classifiers, voting='soft')\n",
    "ensemble.fit(X_train, y_train)\n",
    "y_pred_vot = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  6]\n",
      " [ 6 51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        34\n",
      "           1       0.89      0.89      0.89        57\n",
      "\n",
      "    accuracy                           0.87        91\n",
      "   macro avg       0.86      0.86      0.86        91\n",
      "weighted avg       0.87      0.87      0.87        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, y_pred_vot))\n",
    "print(classification_report(y_test, y_pred_vot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging\n",
    "Now, let build a bagging classifier using Decision Tree. The number of classifier is set to 500.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "num_model = 500\n",
    "#model = LogisticRegression()\n",
    "model = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "bag_clf = BaggingClassifier(base_estimator=model,\n",
    "n_estimators=num_model,\n",
    "bootstrap=True,\n",
    "random_state=1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred_bag = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  5]\n",
      " [ 6 51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84        34\n",
      "           1       0.91      0.89      0.90        57\n",
      "\n",
      "    accuracy                           0.88        91\n",
      "   macro avg       0.87      0.87      0.87        91\n",
      "weighted avg       0.88      0.88      0.88        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_bag))\n",
    "print(classification_report(y_test, y_pred_bag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build a Random Forest classifier with each decision tree has a maximum depth of 5. The\n",
    "number of decision tree is 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "num_model = 500\n",
    "rf_clf = RandomForestClassifier(n_estimators=num_model,\n",
    "max_depth=5, criterion='entropy')\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  4]\n",
      " [ 7 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85        34\n",
      "           1       0.93      0.88      0.90        57\n",
      "\n",
      "    accuracy                           0.88        91\n",
      "   macro avg       0.87      0.88      0.87        91\n",
      "weighted avg       0.88      0.88      0.88        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Stacking classifier consisting of Decision Tree, naive Bayes and Logistic Regression classifiers. The\n",
    "final model is Support Vector Machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "svc = SVC(gamma='auto', probability=True)\n",
    "lgc = LogisticRegression()\n",
    "nbc = GaussianNB()\n",
    "classifiers = []\n",
    "classifiers.append(('c1', dtc))\n",
    "classifiers.append(('c2', nbc))\n",
    "classifiers.append(('c3', lgc))\n",
    "stk_clf = StackingClassifier(estimators=classifiers,\n",
    "final_estimator=svc)\n",
    "stk_clf.fit(X_train, y_train)\n",
    "y_pred_stk = stk_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26  8]\n",
      " [11 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73        34\n",
      "           1       0.85      0.81      0.83        57\n",
      "\n",
      "    accuracy                           0.79        91\n",
      "   macro avg       0.78      0.79      0.78        91\n",
      "weighted avg       0.80      0.79      0.79        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_stk))\n",
    "print(classification_report(y_test, y_pred_stk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "Let’s build an Adaboost classifier. The base model is the decision tree with a maximum depth of\n",
    "1 (only 1 split). The number of base model is 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "num_model = 20\n",
    "#model = LogisticRegression()\n",
    "model = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "ada_clf = AdaBoostClassifier(base_estimator=model,\n",
    "n_estimators=num_model, algorithm='SAMME')\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  4]\n",
      " [ 8 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83        34\n",
      "           1       0.92      0.86      0.89        57\n",
      "\n",
      "    accuracy                           0.87        91\n",
      "   macro avg       0.86      0.87      0.86        91\n",
      "weighted avg       0.87      0.87      0.87        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_ada))\n",
    "print(classification_report(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here, we build a Gradient Boosting classifier. We define several parameters such as follows. loss:\n",
    "for classification, there are two loss functions available, ‘deviance’ or also known as logistic loss\n",
    "(classification with probabilistic outputs) and ‘exponential’ which the gradient boosting becomes\n",
    "the AdaBoost algorithm. max_depth: the depth of the decision tree stump n_estimators: the\n",
    "number of weak classifiers\n",
    "\n",
    "We can also define the following parameters. But we leave them to the default value. The full\n",
    "documentation is available on sklearn website. min_samples_split: the minimum number of\n",
    "samples required to split a node min_samples_leaf: the minimum number of samples required to\n",
    "be at a leaf node max_features: the number of features to consider when looking for the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "num_model = 60\n",
    "gd_model = GradientBoostingClassifier(loss='deviance', n_estimators=num_model,max_depth=1)\n",
    "gd_model.fit(X_train, y_train)\n",
    "y_pred_gd = gd_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  4]\n",
      " [ 5 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        34\n",
      "           1       0.93      0.91      0.92        57\n",
      "\n",
      "    accuracy                           0.90        91\n",
      "   macro avg       0.89      0.90      0.89        91\n",
      "weighted avg       0.90      0.90      0.90        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_gd))\n",
    "print(classification_report(y_test, y_pred_gd))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Exercise\n",
    "\n",
    "The lab exercise uses auto mpg datasets.The data is technical spec of cars. Attribute Information: \n",
    "1.mpg (miles per gallon): continuous \n",
    "2. cylinders: multi-valued discrete \n",
    "3. displacement: continuous\n",
    "4. horsepower: continuous \n",
    "5. weight: continuous \n",
    "6. acceleration: continuous \n",
    "7. model year: multivalued discrete \n",
    "8. origin: multi-valued discrete \n",
    "9. car name: string (unique for each instance)\n",
    "    \n",
    "Build an ensemble model to predict the origin. Experiment with the ensemble methods to achieve\n",
    "the highest accuracy. Use random_state=5 to split the dataset into training and test data.\n",
    "Post your solution on Lab - Ensemble Learning Submission on elearn@usm. Make sure you to\n",
    "include your name, matrix number and lab# on the submission post. Format: in .ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "#auto_pd = pd.read_csv(\"auto_mpg.csv\", sep=\" \")\n",
    "auto_pd = pd.read_csv('auto_mpg.csv', delimiter=r\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   model_year  origin                   car_name  \n",
       "0          70       1  chevrolet chevelle malibu  \n",
       "1          70       1          buick skylark 320  \n",
       "2          70       1         plymouth satellite  \n",
       "3          70       1              amc rebel sst  \n",
       "4          70       1                ford torino  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the first five data\n",
    "auto_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      0\n",
       "weight          0\n",
       "acceleration    0\n",
       "model_year      0\n",
       "origin          0\n",
       "car_name        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of null data based on attributes. In this case 3 column have missing values; (Age, Cabin, and Embarked)\n",
    "auto_pd.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "normData = scaler.fit_transform(auto_pd.iloc[:,0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.617571</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.536150</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.159574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.646739</td>\n",
       "      <td>0.589736</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645995</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.516870</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609819</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.516019</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.212766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.520556</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mpg  cylinders  displacement  horsepower    weight  acceleration  \\\n",
       "0  0.239362        1.0      0.617571    0.456522  0.536150      0.238095   \n",
       "1  0.159574        1.0      0.728682    0.646739  0.589736      0.208333   \n",
       "2  0.239362        1.0      0.645995    0.565217  0.516870      0.178571   \n",
       "3  0.186170        1.0      0.609819    0.565217  0.516019      0.238095   \n",
       "4  0.212766        1.0      0.604651    0.510870  0.520556      0.148810   \n",
       "\n",
       "   model_year  origin  \n",
       "0         0.0       1  \n",
       "1         0.0       1  \n",
       "2         0.0       1  \n",
       "3         0.0       1  \n",
       "4         0.0       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normData_pd = pd.DataFrame(normData)\n",
    "normData_pd.columns = auto_pd.columns[:-1]\n",
    "normData_pd['origin'] = auto_pd['origin']\n",
    "normData_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(normData_pd.iloc[:,0:-1],\n",
    "normData_pd.iloc[:,-1],test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting\n",
    "\n",
    "Let’s build a voting classifier using Decision Tree, Support Vector Machine and Logistic Regression\n",
    "classifiers. The voting scheme is set to ‘soft’. That’s means every individual classifier provides a\n",
    "probability value of an example belongs to a particular target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "svc = SVC(gamma='auto', probability=True) # probability parameter is set to true to output the probability score.\n",
    "lgc = LogisticRegression()\n",
    "classifiers = []\n",
    "classifiers.append(('c1', dtc))\n",
    "classifiers.append(('c2', svc))\n",
    "classifiers.append(('c3', lgc))\n",
    "# voting: hard (class label)/soft (sum of probability)\n",
    "ensemble = VotingClassifier(classifiers, voting='soft')\n",
    "ensemble.fit(X_train, y_train)\n",
    "y_pred_vot = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  2  6]\n",
      " [ 5 10 11]\n",
      " [ 3  2 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.89      0.89        73\n",
      "           2       0.71      0.38      0.50        26\n",
      "           3       0.48      0.76      0.59        21\n",
      "\n",
      "    accuracy                           0.76       120\n",
      "   macro avg       0.70      0.68      0.66       120\n",
      "weighted avg       0.78      0.76      0.75       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, y_pred_vot))\n",
    "print(classification_report(y_test, y_pred_vot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging\n",
    "Now, let build a bagging classifier using Decision Tree. The number of classifier is set to 500.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "num_model = 500\n",
    "#model = LogisticRegression()\n",
    "model = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "bag_clf = BaggingClassifier(base_estimator=model,\n",
    "n_estimators=num_model,\n",
    "bootstrap=True,\n",
    "random_state=1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred_bag = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70  1  2]\n",
      " [ 5  4 17]\n",
      " [ 3  1 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.96      0.93        73\n",
      "           2       0.67      0.15      0.25        26\n",
      "           3       0.47      0.81      0.60        21\n",
      "\n",
      "    accuracy                           0.76       120\n",
      "   macro avg       0.68      0.64      0.59       120\n",
      "weighted avg       0.77      0.76      0.72       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_bag))\n",
    "print(classification_report(y_test, y_pred_bag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build a Random Forest classifier with each decision tree has a maximum depth of 5. The\n",
    "number of decision tree is 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "num_model = 500\n",
    "rf_clf = RandomForestClassifier(n_estimators=num_model,\n",
    "max_depth=5, criterion='entropy')\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67  1  5]\n",
      " [ 7  6 13]\n",
      " [ 4  1 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.92      0.89        73\n",
      "           2       0.75      0.23      0.35        26\n",
      "           3       0.47      0.76      0.58        21\n",
      "\n",
      "    accuracy                           0.74       120\n",
      "   macro avg       0.69      0.64      0.61       120\n",
      "weighted avg       0.77      0.74      0.72       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Stacking classifier consisting of Decision Tree, naive Bayes and Logistic Regression classifiers. The\n",
    "final model is Support Vector Machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "svc = SVC(gamma='auto', probability=True)\n",
    "lgc = LogisticRegression()\n",
    "nbc = GaussianNB()\n",
    "classifiers = []\n",
    "classifiers.append(('c1', dtc))\n",
    "classifiers.append(('c2', nbc))\n",
    "classifiers.append(('c3', lgc))\n",
    "stk_clf = StackingClassifier(estimators=classifiers,\n",
    "final_estimator=svc)\n",
    "stk_clf.fit(X_train, y_train)\n",
    "y_pred_stk = stk_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68  1  4]\n",
      " [ 3 11 12]\n",
      " [ 2  1 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.93      0.93        73\n",
      "           2       0.85      0.42      0.56        26\n",
      "           3       0.53      0.86      0.65        21\n",
      "\n",
      "    accuracy                           0.81       120\n",
      "   macro avg       0.77      0.74      0.72       120\n",
      "weighted avg       0.84      0.81      0.80       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_stk))\n",
    "print(classification_report(y_test, y_pred_stk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "Let’s build an Adaboost classifier. The base model is the decision tree with a maximum depth of\n",
    "1 (only 1 split). The number of base model is 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "num_model = 20\n",
    "#model = LogisticRegression()\n",
    "model = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "ada_clf = AdaBoostClassifier(base_estimator=model,\n",
    "n_estimators=num_model, algorithm='SAMME')\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66  5  2]\n",
      " [ 5  6 15]\n",
      " [ 3  3 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.90      0.90        73\n",
      "           2       0.43      0.23      0.30        26\n",
      "           3       0.47      0.71      0.57        21\n",
      "\n",
      "    accuracy                           0.73       120\n",
      "   macro avg       0.60      0.62      0.59       120\n",
      "weighted avg       0.72      0.72      0.71       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_ada))\n",
    "print(classification_report(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "num_model = 60\n",
    "gd_model = GradientBoostingClassifier(loss='deviance', n_estimators=num_model,max_depth=1)\n",
    "gd_model.fit(X_train, y_train)\n",
    "y_pred_gd = gd_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66  3  4]\n",
      " [ 7  6 13]\n",
      " [ 3  0 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.90      0.89        73\n",
      "           2       0.67      0.23      0.34        26\n",
      "           3       0.51      0.86      0.64        21\n",
      "\n",
      "    accuracy                           0.75       120\n",
      "   macro avg       0.68      0.66      0.62       120\n",
      "weighted avg       0.76      0.75      0.73       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_gd))\n",
    "print(classification_report(y_test, y_pred_gd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
